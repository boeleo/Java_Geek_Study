2.（必做）设计对前面的订单表数据进行水平分库分表，拆分 2 个库，每个库 16 张表。并在新结构在演示常见的增删改查操作。代码、sql 和配置文件，上传到 Github。

为了简化代码，下面使用简化的订单表格
0) 准备数据库, 在用Docker搭建好的MySQL server中创建两个数据库:
```
drop database if exists ds0;
drop database if exists ds1; 
create database ds0;
create database ds1;
```
1) 在两个库中分别各自创建16张表结构如下:
```
CREATE TABLE IF NOT EXISTS `ds0`.`t_order_0`(
   `id` INT UNSIGNED AUTO_INCREMENT,
   `date` DATETime,
   `user_id` bigint NOT NULL COMMENT 'user_id',
   `order_id` bigint NOT NULL COMMENT 'order_id',
   PRIMARY KEY ( `id` )
)ENGINE=InnoDB DEFAULT CHARSET=utf8;
...
CREATE TABLE IF NOT EXISTS `ds0`.`t_order_15`(
   `id` INT UNSIGNED AUTO_INCREMENT,
   `date` DATETime,
   `user_id` bigint NOT NULL COMMENT 'user_id',
   `order_id` bigint NOT NULL COMMENT 'order_id',
   PRIMARY KEY ( `id` )
)ENGINE=InnoDB DEFAULT CHARSET=utf8;
```
2) 在Maven工程中加入shardingsphere-jdbc-core的依赖；
3) 创建JUnit测试用例如下:
```
package com.hebaojia;

import java.io.IOException;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;
import java.util.Collections;
import java.util.HashMap;
import java.util.Map;
import java.util.Properties;
import javax.sql.DataSource;
import org.apache.shardingsphere.driver.api.ShardingSphereDataSourceFactory;
import org.apache.shardingsphere.infra.config.algorithm.ShardingSphereAlgorithmConfiguration;
import org.apache.shardingsphere.sharding.api.config.ShardingRuleConfiguration;
import org.apache.shardingsphere.sharding.api.config.rule.ShardingTableRuleConfiguration;
import org.apache.shardingsphere.sharding.api.config.strategy.sharding.StandardShardingStrategyConfiguration;
import org.junit.jupiter.api.Test;

import com.zaxxer.hikari.HikariDataSource;

class TestShardingSphereCase {

	@Test
	void test() throws SQLException, IOException {
		
		// 配置数据源
		Map<String, DataSource> dataSourceMap = new HashMap<>();

		// 配置ds0
		HikariDataSource ds0 = new HikariDataSource();
		ds0.setDriverClassName("com.mysql.cj.jdbc.Driver");
		ds0.setJdbcUrl("jdbc:mysql://localhost:13306/ds0");
		ds0.setUsername("root");
		ds0.setPassword("123456");
		dataSourceMap.put("ds0", ds0);

		// 配置ds1
		HikariDataSource ds1 = new HikariDataSource();
		ds1.setDriverClassName("com.mysql.cj.jdbc.Driver");
		ds1.setJdbcUrl("jdbc:mysql://localhost:13306/ds1");
		ds1.setUsername("root");
		ds1.setPassword("123456");
		dataSourceMap.put("ds1", ds1);
		
		// 配置 t_order 表规则，两个库，各自16张表
		ShardingTableRuleConfiguration orderTableRuleConfig = new ShardingTableRuleConfiguration("t_order", "ds${0..1}.t_order_${0..15}");

		// 配置分库策略，按照user_id分库
		orderTableRuleConfig.setDatabaseShardingStrategy(new StandardShardingStrategyConfiguration("user_id", "dbShardingAlgorithm"));

		// 配置分表策略，按照order_id分表
		orderTableRuleConfig.setTableShardingStrategy(new StandardShardingStrategyConfiguration("order_id", "tableShardingAlgorithm"));

		// 省略配置 t_order_item 表规则...
		// ...

		// 配置分片规则
		ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration();
		shardingRuleConfig.getTables().add(orderTableRuleConfig);

		// 配置分库算法
		Properties dbShardingAlgorithmrProps = new Properties();
		dbShardingAlgorithmrProps.setProperty("algorithm-expression", "ds${user_id % 2}");
		shardingRuleConfig.getShardingAlgorithms().put("dbShardingAlgorithm", new ShardingSphereAlgorithmConfiguration("INLINE", dbShardingAlgorithmrProps));

		// 配置分表算法
		Properties tableShardingAlgorithmrProps = new Properties();
		tableShardingAlgorithmrProps.setProperty("algorithm-expression", "t_order_${order_id % 16}");
		shardingRuleConfig.getShardingAlgorithms().put("tableShardingAlgorithm", new ShardingSphereAlgorithmConfiguration("INLINE", tableShardingAlgorithmrProps));
		
		// Create ShardingSphereDataSource
		DataSource dataSource = ShardingSphereDataSourceFactory.createDataSource(dataSourceMap, Collections.singleton(shardingRuleConfig), new Properties());
		System.out.println("DataSource: " + dataSource);

		// 插入数据
		Connection connection = dataSource.getConnection();
		String sql = "INSERT INTO ds.t_order (id, date, user_id, order_id) VALUES (?,Now(),?, ?);";
		PreparedStatement ps = connection.prepareStatement(sql);
		
		int count = 0;
		final int batchSize = 100000;
		long start = System.currentTimeMillis();
		System.err.println("Start.....");
		for (int i = count; i<batchSize+count; i++) {
			ps.setInt(1, i);
			ps.setInt(2, i % 2); // 假装user_id只有0和1
			ps.setInt(3, i);
			ps.addBatch();
			System.err.println(i + "," + i % 2 % 2 + "," + i % 16);
		}
		ps.executeBatch();
		ps.close();
		connection.close();
		long end = System.currentTimeMillis();
		System.err.println("End: "+(end-start));
	}
}
```